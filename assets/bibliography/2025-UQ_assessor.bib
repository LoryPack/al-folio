@article{shorinwa2024survey,
  title={A Survey on Uncertainty Quantification of Large Language Models: Taxonomy, Open Research Challenges, and Future Directions},
  author={Shorinwa, Ola and Mei, Zhiting and Lidard, Justin and Ren, Allen Z and Majumdar, Anirudha},
  journal={arXiv preprint arXiv:2412.05563},
  year={2024},
  url={https://arxiv.org/abs/2412.05563}
}

@article{kadavath2022language,
  title={Language models (mostly) know what they know},
  author={Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, Scott Johnston, Sheer El-Showk, Andy Jones, Nelson Elhage, Tristan Hume, Anna Chen, Yuntao Bai, Sam Bowman, Stanislav Fort, Deep Ganguli, Danny Hernandez, Josh Jacobson, Jackson Kernion, Shauna Kravec, Liane Lovitt, Kamal Ndousse, Catherine Olsson, Sam Ringer, Dario Amodei, Tom Brown, Jack Clark, Nicholas Joseph, Ben Mann, Sam McCandlish, Chris Olah, and Jared Kaplan},
  journal={arXiv preprint arXiv:2207.05221},
  year={2022},
  url={https://arxiv.org/abs/2207.05221}
}

@article{lin2022teaching,
  title={Teaching models to express their uncertainty in words},
  author={Stephanie Lin, Jacob Hilton, and Owain Evans},
  journal={arXiv preprint arXiv:2205.14334},
  year={2022},
  url={https://arxiv.org/abs/2205.14334}
}

@article{kuhn2023semantic,
  title={Semantic uncertainty: Linguistic invariances for uncertainty estimation in natural language generation},
  author={Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar},
  journal={arXiv preprint arXiv:2302.09664},
  year={2023},
  url={https://arxiv.org/abs/2302.09664}
}

@article{ferrando2024entity,
  title={Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models},
  author={Javier Ferrando, Oscar Obeso, Senthooran Rajamanoharan, and Neel Nanda},
  journal={arXiv preprint arXiv:2411.14257},
  year={2024},
  url={https://arxiv.org/abs/2411.14257}
}

@article{sam2025predicting,
  title={Predicting the Performance of Black-box LLMs through Self-Queries},
  author={Sam, Dylan and Finzi, Marc and Kolter, J Zico},
  journal={arXiv preprint arXiv:2501.01558},
  year={2025},
  url={https://arxiv.org/abs/2501.01558}
}



@article{pawitan2024confidence,
  title={Confidence in the Reasoning of Large Language Models},
  author={Pawitan, Yudi, and Chris Holmes},
  journal={arXiv preprint arXiv:2412.15296},
  year={2024},
  url={https://arxiv.org/abs/2412.15296}
}

@inproceedings{hernandez2022training,
  title={Training on the test set: Mapping the system-problem space in AI},
  author={Jos{\'e} Hern{\'a}ndez-Orallo, Wout Schellaert, and Fernando Mart{\'i}nez-Plumed},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={36},
  pages={12256--12264},
  year={2022},
  url={https://ojs.aaai.org/index.php/AAAI/article/view/21487}
}

@article{schellaert2024analysing,
  title={Analysing the predictability of language model performance},
  author={Wout Schellaert, Fernando Mart{\'i}nez-Plumed, and Jos{\'e} Hern{\'a}ndez-Orallo},
  journal={ACM Transactions on Intelligent Systems and Technology},
  year={2024},
  url={https://dl.acm.org/doi/10.1145/3706118}
}

@inproceedings{zhou2022reject,
  title={Reject before you run: Small assessors anticipate big language models},
  author={Lexin Zhou, Fernando Mart{\'i}nez-Plumed, Jos{\'e} Hern{\'a}ndez-Orallo, C{\`e}sar Ferri, and Wout Schellaert},
  booktitle={EBeM@ IJCAI},
  year={2022},
  url={https://ceur-ws.org/Vol-3169/paper4.pdf}
}

@article{pacchiardi2024instances,
  title={100 instances is all you need: predicting the success of a new LLM on unseen data by testing on a few instances},
  author={Lorenzo Pacchiardi, Lucy G. Cheke, and Jos{\'e} Hern{\'a}ndez-Orallo},
  journal={arXiv preprint arXiv:2409.03563},
  year={2024},
  url={https://arxiv.org/abs/2409.03563}
}

@article{wen2024mislead,
  title={Language models learn to mislead humans via RLHF},
  author={Jiaxin Wen, Ruiqi Zhong, Akbir Khan, Ethan Perez, Jacob Steinhardt, Minlie Huang, Samuel R. Bowman, He He, and Shi Feng},
  journal={arXiv preprint arXiv:2409.12822},
  year={2024},
  url={https://arxiv.org/abs/2409.12822}
}

@article{hu2024routerbench,
  title={Routerbench: A benchmark for multi-LLM routing system},
  author={Qitian Jason Hu, Jacob Bieker, Xiuyu Li, Nan Jiang, Benjamin Keigwin, Gaurav Ranganath, Kurt Keutzer, and Shriyash Kaustubh Upadhyay},
  journal={arXiv preprint arXiv:2403.12031},
  year={2024},
  url={https://arxiv.org/abs/2403.12031}
}

@article{cohen2024idk,
  title={I Don't Know: Explicit Modeling of Uncertainty with an [IDK] Token},
  author={Cohen, Roi and Dobler, Konstantin and Biran, Eden and de Melo, Gerard},
  journal={arXiv preprint arXiv:2412.06676},
  year={2024},
  url={https://arxiv.org/abs/2412.06676}
}

@article{burger2024truth,
  title={Truth is universal: Robust detection of lies in LLMs},
  author={B{\"u}rger, Lennart, Fred A. Hamprecht, and Boaz Nadler},
  journal={arXiv preprint arXiv:2407.12831},
  year={2024},
  url={https://arxiv.org/abs/2407.12831}
}

@article{azaria2023internal,
  title={The internal state of an LLM knows when it's lying},
  author={Azaria, Amos, and Tom Mitchell},
  journal={arXiv preprint arXiv:2304.13734},
  year={2023},
  url={https://arxiv.org/abs/2304.13734}
}

@article{weij2024sandbagging,
  title={AI Sandbagging: Language Models can Strategically Underperform on Evaluations},
  author={van der Weij, Teun and Hofst{\"a}tter, Felix and Jaffe, Ollie and Brown, Samuel F and Ward, Francis Rhys},
  journal={arXiv preprint arXiv:2406.07358},
  year={2024},
  url={https://arxiv.org/abs/2406.07358}
}

@article{zou2022forecasting,
  title={Forecasting future world events with neural networks},
  author={Zou, Andy and Xiao, Tristan and Jia, Ryan and Kwon, Joe and Mazeika, Mantas and Li, Richard and Song, Dawn and Steinhardt, Jacob and Evans, Owain and Hendrycks, Dan},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27293--27305},
  year={2022},
  url={https://arxiv.org/abs/2206.15474}
}

@article{schoenegger2024wisdom,
  title={Wisdom of the silicon crowd: LLM ensemble prediction capabilities match human crowd accuracy},
  author={Schoenegger, Philipp and Tuminauskaite, Indre and Park, Peter S and Tetlock, Philip E},
  journal={arXiv preprint arXiv:2402.19379},
  year={2024},
  url={https://arxiv.org/abs/2402.19379}
}

@article{halawi2024forecasting,
  title={Approaching Human-Level Forecasting with Language Models},
  author={Halawi, Danny and Zhang, Fred and Yueh-Han, Chen and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2402.18563},
  year={2024},
  url={https://arxiv.org/abs/2402.18563}
}

@article{nath2024goal,
  title={Learning Goal-Conditioned Representations for Language Reward Models},
  author={Nath, Vaskar and Slack, Dylan and Da, Jeff and Ma, Yuntao and Zhang, Hugh and Whitehead, Spencer and Hendryx, Sean},
  journal={arXiv preprint arXiv:2407.13887},
  year={2024},
  url={https://arxiv.org/abs/2407.13887}
}

@misc{carlini2024gpt,
  title={A GPT-4 capability forecasting challenge},
  author={Nicholas Carlini},
  howpublished={Blog post},
  year={2024},
  url={https://nicholas.carlini.com/writing/llm-forecast/question/Capital-of-Paris}
}

@inproceedings{vafa2024large,
  title={Do large language models perform the way people expect? measuring the human-generalization function},
  author={Keyon Vafa, Ashesh Rambachan, and Sendhil Mullainathan},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024},
  url={https://arxiv.org/abs/2406.01382}
}

@article{zhou2024larger,
  title={Larger and more instructable language models become less reliable},
  author={Lexin Zhou, Wout Schellaert, Fernando Mart{\'i}nez Plumed, Yael Moros-Daval, C{\`e}sar Ferri, and Jos{\'e} Hern{\'a}ndez-Orallo},
  journal={Nature},
  volume={634},
  pages={61--68},
  year={2024},
  url={https://www.nature.com/articles/s41586-024-07930-y}
}

@article{steyvers2025large,
  title={What large language models know and what people think they know},
  author={Steyvers, Mark and Tejeda, Heliodoro and Kumar, Aakriti and Belem, Catarina and Karny, Sheer and Hu, Xinyue and Mayer, Lukas W and Smyth, Padhraic},
  journal={Nature Machine Intelligence},
  pages={1--11},
  year={2025},
  publisher={Nature Publishing Group UK London},
  url={https://www.nature.com/articles/s42256-024-00976-7}
}

@article{dhole2022augmenter,
  title={NL-augmenter: A framework for task-sensitive natural language augmentation},
  author={Dhole, Kaustubh D and Gangal, Varun and Gehrmann, Sebastian and Gupta, Aadesh and Li, Zhenhao and Mahamood, Saad and Mahendiran, Abinaya and Mille, Simon and Shrivastava, Ashish and Tan, Samson and others},
  journal={arXiv preprint arXiv:2112.02721},
  year={2022},
  url={https://arxiv.org/abs/2112.02721}
}

@article{shen2024jailbreak,
  title={Do anything now: Characterizing and evaluating in-the-wild jailbreak prompts on large language models},
  author={Xinyue Shen, Zeyuan Chen, Michael Backes, Yun Shen, and Yang Zhang},
  journal={arXiv preprint arXiv:2308.03825},
  year={2024},
  url={https://arxiv.org/abs/2308.03825}
}

@article{hendrickx2024reject,
  title={Machine learning with a reject option: A survey},
  author={Hendrickx, Kilian and Perini, Lorenzo and Van der Plas, Dries and Meert, Wannes and Davis, Jesse},
  journal={Machine Learning},
  volume={113},
  number={5},
  pages={3073--3110},
  year={2024},
  url={https://link.springer.com/article/10.1007/s10994-024-06534-x}
}
